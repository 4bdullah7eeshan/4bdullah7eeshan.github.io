[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Abdullah Zeeshan",
    "section": "",
    "text": "I am a CF APMP certified professional transitioning into the world of bids & proposals.\n\n\n\n\nI started my professional journey working in a Hyderabad, India based NGO Youngistaan Foundation in its educational program Bright Spark. The program served the educational needs of the underprivileged children who live in slum areas.\nDuring my time, I went on to take a diverse set of roles ranging from teaching, mentorship, curriculum designing, coordination, and content creation.\nFollowing are some highlighted projects I was involved in:\n\nCyber Congress Project: Worked as a Content Designer, Volunteer Lead, and Coordinator on a statewide 10-month Cyber Safety project targeting students of more than 3000+ government schools teaming with the Telangana Police Department, the SHE Team Hyderabad City, the Women Safety Wing, Telangana State, the NICSI and the educational partner and lead trainer Mr. Rakshit Tandon.\nSocial Emotional Learning Project: Worked closely with underprivileged children on developing and honing critical social-emotional skills and attitudes of resilience, self-advocacy, empathy, and learning. Actively engaged in preparing, planning and implementing CASEL’s evidence-based SEL framework.\nEducational Project: Helped children aged 5 to 16 build foundation skills in Math, English, Logical Reasoning, and Science, and took them to educational trips, theatre shows, and field trips for a holistic learning experience.\nTheatre Art Project: Co-ordinated a 2-month-long theatre workshop that was conducted by eminent theatre artist Vinay Varma with 13 underprivileged children from a learning pocket in a political satire, Kane Raja ki Nagari. Later, these children performed the play in one of the busiest theatres of Hyderabad.\nChild Safety Project: Facilitated a session revolving around educating children on “Good and Bad Touch” to keep them ready to tackle such a situation.\nRubaroo Fellowship: Affiliated with Rubaroo for a year in their “Nurturer Program” fellowship.\n\n\n\n\nAfter having gained experience and exposure to education, I later joined a Hyderabad based private school and worked there as a Math and Physics teacher for classes 9th and 10th and a Life Skills Trainer for classes 7th and 8th.\nMy goal was to make my students fall in love with Math and Physics and make learning a wholesome and a joyous experience.\nI brought creativity in my classrooms by including activities, games, collaboration in my lesson plans.\n\n\n\nI joined a B2B ed-tech startup that provided educational content creation services to organizations.\nI worked there as an SME and an SME Lead wearing multiple hats. I created Math educational content in both video and text formats, led a mid-size team of educators, assisted in pre-sales activities, handled operations and project management side of the business complying with clients requirements, recruited and onboarded educators on my team, held marketing campaigns, and so on.\nThis was my first hand experience into the corporate world and it taught me a lot about how B2B organizations worked. Since, it was a startup, I was able to get my hands across all the different departments of the company.\n\n\n\nI took a conscious decision to go on a career break to explore my tech aspirations. Over the course of 3 years, I enrolled in the following programs with the aim learning and exploring Data Science and Software Engineering.\n\nIndian Institute of Technology Madras (IIT M)’ BS in Data Science & Applications, 2021 - 2023.\nfast.ai’s Practical Deep Learning for Coders, 2023.\nThe Odin Project’s Full Stack Web Development course, 2024.\n\nI did two internships in this duration.\nThe first one was a summer internship in 2022 at IIT Ropar under the expert guidance of Professor Dr. Sudarshan Iyengar during my internship, I primarily designed, developed, and fine-tuned NLP models using Transformers and BERT, implemented from the research papers Attention Is All You Need and BERT, respectively.\nThe second one was at the end of 2024, in a mid-sized IT services company where I worked as a Developer and a Team Lead working on various client projects and leading both frontend and backend teams for cross-collaboration.\nMy explorations in tech equipped me with problem solving skills, a technical acumen, and way to look at technology from the builder’s eye!\n\n\n\nIn 2025, I got to know about this niche profession of Bids & Proposals when I was having a conversation with my father. I started doing some research and a whole new world open up in front of me. I was surprised by its diversity - writing, technical acumen, understanding customers needs, and most importantly a seat that gives a 360 degree view of the complete business development cycle. I got to know about APMP and after a few weeks I decided to transition into this profession. I studied for the APMP Foundation Level Exam and got certified.\n\n\n\n\nAPMP Foundation Level Certification (CF APMP), APMG International, June 2025, View Credentials\n\n\n\nSwimming, Strength Training, Reading, Watching thriller movies, Gaming, Watching football, Philosophy, AI, ML, Programming, Psychology, Liberal Arts"
  },
  {
    "objectID": "about.html#about",
    "href": "about.html#about",
    "title": "Abdullah Zeeshan",
    "section": "",
    "text": "I am a CF APMP certified professional transitioning into the world of bids & proposals.\n\n\n\n\nI started my professional journey working in a Hyderabad, India based NGO Youngistaan Foundation in its educational program Bright Spark. The program served the educational needs of the underprivileged children who live in slum areas.\nDuring my time, I went on to take a diverse set of roles ranging from teaching, mentorship, curriculum designing, coordination, and content creation.\nFollowing are some highlighted projects I was involved in:\n\nCyber Congress Project: Worked as a Content Designer, Volunteer Lead, and Coordinator on a statewide 10-month Cyber Safety project targeting students of more than 3000+ government schools teaming with the Telangana Police Department, the SHE Team Hyderabad City, the Women Safety Wing, Telangana State, the NICSI and the educational partner and lead trainer Mr. Rakshit Tandon.\nSocial Emotional Learning Project: Worked closely with underprivileged children on developing and honing critical social-emotional skills and attitudes of resilience, self-advocacy, empathy, and learning. Actively engaged in preparing, planning and implementing CASEL’s evidence-based SEL framework.\nEducational Project: Helped children aged 5 to 16 build foundation skills in Math, English, Logical Reasoning, and Science, and took them to educational trips, theatre shows, and field trips for a holistic learning experience.\nTheatre Art Project: Co-ordinated a 2-month-long theatre workshop that was conducted by eminent theatre artist Vinay Varma with 13 underprivileged children from a learning pocket in a political satire, Kane Raja ki Nagari. Later, these children performed the play in one of the busiest theatres of Hyderabad.\nChild Safety Project: Facilitated a session revolving around educating children on “Good and Bad Touch” to keep them ready to tackle such a situation.\nRubaroo Fellowship: Affiliated with Rubaroo for a year in their “Nurturer Program” fellowship.\n\n\n\n\nAfter having gained experience and exposure to education, I later joined a Hyderabad based private school and worked there as a Math and Physics teacher for classes 9th and 10th and a Life Skills Trainer for classes 7th and 8th.\nMy goal was to make my students fall in love with Math and Physics and make learning a wholesome and a joyous experience.\nI brought creativity in my classrooms by including activities, games, collaboration in my lesson plans.\n\n\n\nI joined a B2B ed-tech startup that provided educational content creation services to organizations.\nI worked there as an SME and an SME Lead wearing multiple hats. I created Math educational content in both video and text formats, led a mid-size team of educators, assisted in pre-sales activities, handled operations and project management side of the business complying with clients requirements, recruited and onboarded educators on my team, held marketing campaigns, and so on.\nThis was my first hand experience into the corporate world and it taught me a lot about how B2B organizations worked. Since, it was a startup, I was able to get my hands across all the different departments of the company.\n\n\n\nI took a conscious decision to go on a career break to explore my tech aspirations. Over the course of 3 years, I enrolled in the following programs with the aim learning and exploring Data Science and Software Engineering.\n\nIndian Institute of Technology Madras (IIT M)’ BS in Data Science & Applications, 2021 - 2023.\nfast.ai’s Practical Deep Learning for Coders, 2023.\nThe Odin Project’s Full Stack Web Development course, 2024.\n\nI did two internships in this duration.\nThe first one was a summer internship in 2022 at IIT Ropar under the expert guidance of Professor Dr. Sudarshan Iyengar during my internship, I primarily designed, developed, and fine-tuned NLP models using Transformers and BERT, implemented from the research papers Attention Is All You Need and BERT, respectively.\nThe second one was at the end of 2024, in a mid-sized IT services company where I worked as a Developer and a Team Lead working on various client projects and leading both frontend and backend teams for cross-collaboration.\nMy explorations in tech equipped me with problem solving skills, a technical acumen, and way to look at technology from the builder’s eye!\n\n\n\nIn 2025, I got to know about this niche profession of Bids & Proposals when I was having a conversation with my father. I started doing some research and a whole new world open up in front of me. I was surprised by its diversity - writing, technical acumen, understanding customers needs, and most importantly a seat that gives a 360 degree view of the complete business development cycle. I got to know about APMP and after a few weeks I decided to transition into this profession. I studied for the APMP Foundation Level Exam and got certified.\n\n\n\n\nAPMP Foundation Level Certification (CF APMP), APMG International, June 2025, View Credentials\n\n\n\nSwimming, Strength Training, Reading, Watching thriller movies, Gaming, Watching football, Philosophy, AI, ML, Programming, Psychology, Liberal Arts"
  },
  {
    "objectID": "posts/frolicking-with-ai-generated-art/index.html",
    "href": "posts/frolicking-with-ai-generated-art/index.html",
    "title": "Frolicking With AI Generated Art",
    "section": "",
    "text": "We are living in the times where all art forms that were solely reserved for humans is slowly being generated by AI. Be it the art of writing, music, images, video creation, and even pure art!\n2022 began wonderfully with the advent of AI systems that could create art with mere textual descriptions. Platforms like DALL.E.2, Mindjourney, and many more have emerged gaining high popularity across the world.\nI was a little away from the AI buzz news, and I got to know about it a little later when I was listening to Lesson 1 of the Practical Deep Learning for Coders course offered by fast.ai. Jeremy Howard, the instructor of the course shared these amazing explorations done by people who toyed with this new state of the art AI beauty!\nI had to go and explore them myself. I just had to! I mean, just look at these.\nSo, I signed up of DALL.E.2 and started to experiment with it. In this blog I am sharing some of my explorations which were mind bending."
  },
  {
    "objectID": "posts/frolicking-with-ai-generated-art/index.html#a-challenge-i-faced",
    "href": "posts/frolicking-with-ai-generated-art/index.html#a-challenge-i-faced",
    "title": "Frolicking With AI Generated Art",
    "section": "A Challenge I Faced",
    "text": "A Challenge I Faced\nI had this wonderful machine infront of me, that was waiting for my textual instructions to create art! The first challenge I faced was the inability to express what I wanted to see. I mean, I am a human after all, and I must be really good with the primary skills that I possess as a human, to articulate myself. But, there I was staring blankly at the search bar, thinking what to type. All I could come up with was “fox eating an ice cream”, which is a good thing to begin with. It did give me results of “a fox eating an ice cream”.\n\n\n\nDALL.E.2 Illustration\n\n\nBut I couldn’t articulate longer descriptive sentences. I spent some time thinking and grabbing ideas from other peoples search styles and finally I was able to describe something expressive and detailed. Let me show you its wonders."
  },
  {
    "objectID": "posts/frolicking-with-ai-generated-art/index.html#my-dall.e.2-explorations",
    "href": "posts/frolicking-with-ai-generated-art/index.html#my-dall.e.2-explorations",
    "title": "Frolicking With AI Generated Art",
    "section": "My DALL.E.2 Explorations",
    "text": "My DALL.E.2 Explorations\n\nabstract portrait of a man made with flowers\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nabstract art of a robot teaching math to kids\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nscholastic deep explorations in snow\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3d render of a book made with melting cheese placed on dining table\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\na flower riding a horse in space meeting aliens\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\na dog wearing glasses teaching robots in a class\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsamurai fighting a battle with a katana on fire\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIsn’t it amazing?! Feel free to try yourself too!"
  },
  {
    "objectID": "posts/frolicking-with-ai-generated-art/index.html#a-minor-epiphany",
    "href": "posts/frolicking-with-ai-generated-art/index.html#a-minor-epiphany",
    "title": "Frolicking With AI Generated Art",
    "section": "A Minor Epiphany",
    "text": "A Minor Epiphany\nI might be stepping on a slightly contreversial theme here, but on a bit of a different philosophical tangent, I had a minor epiphany that I want to share.\nAs I was struggling to articulate descriptions of art I wanted see, it crossed my mind that although we are moving towards this amazing world of possibilities where AI can do brilliantly magical stuff, but we as humans are also losing parts of ourselves which were innate to our cognitive abilities. We are in a sense delegating our cognitive tools to AI and dumbing ourselves down. I mean what will be left of us when every possible capability of our minds is transfered to AI. There were times, when we would smirk at the concept of doing mental arithmetics thinking that our mobile phones can do it for us, which they can for sure, very accurately. But we are losing our mental abilities to machines to a point that we can not even use it the way we want.\nTo end on a lighter note, here are a few art to cheer you up!\n\n\nfox walking down the street to a bar on a rainy night holding an umbrella"
  },
  {
    "objectID": "posts/segmentation/segmentation.html",
    "href": "posts/segmentation/segmentation.html",
    "title": "Oh! Segmentation Tasks, Segmentation Tasks",
    "section": "",
    "text": "Street view image created using Stable Diffusion\n\n\nCan you recognize various objects from the above picture? Our eyes have the ability to see a complete image and recognize the distinguishing objects from it. We know there is a car on the left, a person ahead on the right, etc. Can we make computers do this?! Let us find out!"
  },
  {
    "objectID": "posts/segmentation/segmentation.html#introduction",
    "href": "posts/segmentation/segmentation.html#introduction",
    "title": "Oh! Segmentation Tasks, Segmentation Tasks",
    "section": "",
    "text": "Street view image created using Stable Diffusion\n\n\nCan you recognize various objects from the above picture? Our eyes have the ability to see a complete image and recognize the distinguishing objects from it. We know there is a car on the left, a person ahead on the right, etc. Can we make computers do this?! Let us find out!"
  },
  {
    "objectID": "posts/segmentation/segmentation.html#what-is-segmentation",
    "href": "posts/segmentation/segmentation.html#what-is-segmentation",
    "title": "Oh! Segmentation Tasks, Segmentation Tasks",
    "section": "What Is Segmentation?",
    "text": "What Is Segmentation?\nSegmentation refers to the process of dividing an image into multiple regions or segments, where each segment corresponds to a specific object or background.\nThe goal of a segmentation model in Deep Learning is to recognize the content of every individual pixel in an image thereby localizing objects in it.\nThis task is very important for self-driving cars, for example. If a self-driving car doesn’t know where a pedestrian is, then it doesn’t know how to avoid one!"
  },
  {
    "objectID": "posts/segmentation/segmentation.html#building-a-segmentation-model",
    "href": "posts/segmentation/segmentation.html#building-a-segmentation-model",
    "title": "Oh! Segmentation Tasks, Segmentation Tasks",
    "section": "Building A Segmentation Model",
    "text": "Building A Segmentation Model\nWe will train a simple segmentation model using the fastai library.\n\n\n\nSource: https://giphy.com/gifs/starwars-star-wars-the-last-jedi-xT9Iguc1FSPtLmCw5W\n\n\n\nInstalling & Importing Relevant Libraries\nWe will install the fastai software and export all the vision libraries, since this is computer vision task.\n\n!pip install -Uqqq fastai\n\n\nfrom fastai.vision.all import *\n\n\n\nGetting Training Data\nWe will use a subset of the CamVid dataset from the paper “Semantic Object Classes in Video: A High-Definition Ground Truth Database” by Gabriel J. Brostow et al.\nThe following code gets the data for us!\n\npath = untar_data(URLs.CAMVID_TINY)\npath\n\n\n\n\n\n\n    \n      \n      100.18% [2318336/2314212 00:00&lt;00:00]\n    \n    \n\n\nPath('/root/.fastai/data/camvid_tiny')\n\n\nNow that we got the data, before using it for training our model, we we will have to specify fastai what kind of data we have, how it is structured, and for what task are we going to use it.\nThe following code does this.\n\ndls = SegmentationDataLoaders.from_label_func(path, bs = 8, fnames = get_image_files(path/'images'),\n                                             label_func = lambda o: path/'labels'/f'{o.stem}_P{o.suffix}',\n                                             codes = np.loadtxt(path/'codes.txt', dtype = str))\n\nLet us have a look at our data!\n\ndls.show_batch()\n\n\n\n\n\n\n\n\nThese are the 8 images for which we will train a model that can recognize its objects.\n\n\nUsing A Learner & Fine-tuning\nWe will use a unet learner and resenet34 architecture, a pre-trained model to fine-tune it for our task of segmentation.\n\nlearner = unet_learner(dls, resnet34)\nlearner.fine_tune(10)\n\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n100%|██████████| 83.3M/83.3M [00:00&lt;00:00, 298MB/s]\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\ntime\n\n\n\n\n0\n2.925367\n1.908659\n00:11\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\ntime\n\n\n\n\n0\n1.629299\n1.505528\n00:01\n\n\n1\n1.446579\n1.181775\n00:01\n\n\n2\n1.380383\n1.429530\n00:01\n\n\n3\n1.333090\n1.063483\n00:01\n\n\n4\n1.237765\n1.000342\n00:01\n\n\n5\n1.134848\n0.884875\n00:01\n\n\n6\n1.037858\n0.903598\n00:01\n\n\n7\n0.948801\n0.812336\n00:01\n\n\n8\n0.874415\n0.829520\n00:01\n\n\n9\n0.816568\n0.826488\n00:01\n\n\n\n\n\nThe training is done! It trained for about 15-20 sec. \nLet us see the results!\n\nlearner.show_results(figsize = (7, 8))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVoila! On the left are the original images, and on the right are the ones that were segmented by our model. We can clearly see that it did a pretty good job in recognizing the pixels! For some, it got a few things wrong, but for most of them it got right!\nTo summarize, computers now can identify objects in an image, that too pretty well!"
  },
  {
    "objectID": "posts/segmentation/segmentation.html#a-poem",
    "href": "posts/segmentation/segmentation.html#a-poem",
    "title": "Oh! Segmentation Tasks, Segmentation Tasks",
    "section": "A Poem",
    "text": "A Poem\nHere is a poem generated by ChatGPT on Segmentation.\n\nOh, segmentation task, segmentation task, Dividing images is its awesome task. To split an image into regions fine, And label each one, that is the line.\nSegmentation finds objects in a snap, And separates them from the background’s trap. In autonomous cars it plays a role, To avoid obstacles and reach the goal.\nIn medical images it helps a lot, To pinpoint where the issues are wrought. Convolutional neural networks take charge, And extract features like a boss, it’s large!\nThey label each pixel with a keen eye, And categorize them, oh so sly. Object recognition, it can aid, And much more, the list won’t fade.\nSegmentation task, oh how grand, In computer vision, it’s in high demand! Precise and accurate, it must be, So many applications, it sets us free!"
  },
  {
    "objectID": "posts/teaching-ai-some-geography/continents_classifier.html",
    "href": "posts/teaching-ai-some-geography/continents_classifier.html",
    "title": "Teaching AI Some Geography",
    "section": "",
    "text": "Lesson 1 of the Practical Deep Learning for Coders course offered by fast.ai gets hands-on on building an image classifier of your choice pretty quickly without any hastles from the get-go!\nI tried to build an image classifier that could classify the 7 continents based on their map images. And boy let me tell you, I was unbelievably amazed by its results.\nLet me show you how I did it! Feel free to try yourself on Colab or any platform of your choice!"
  },
  {
    "objectID": "posts/teaching-ai-some-geography/continents_classifier.html#setting-up",
    "href": "posts/teaching-ai-some-geography/continents_classifier.html#setting-up",
    "title": "Teaching AI Some Geography",
    "section": "Setting Up",
    "text": "Setting Up\n\nInstall Packages\nWe begin by installing fastbook and duckduckgo_search. The formers allows us to access the fast.ai library that will help us build our image classifier and the latter allows us to access DuckDuckGo search engine features to search, get, and download our images for training.\n\n!pip install -Uqq fastbook duckduckgo_search\n\n\n\nImport Relevant Libraries\nWe import the relevant libraries. More about them here.\n\nfrom duckduckgo_search import ddg_images\nfrom fastcore.all import *\nfrom fastdownload import download_url\nfrom fastai.vision.all import *\n\n\n\nSetup A System For Getting Images\nHere, we create a handy little function that can search for a specific term on DuckDuckGo image searches and get its URLs\n\ndef search_images(term, max_images=30):\n    print(f\"Searching for '{term}'\")\n    return L(ddg_images(term, max_results=max_images)).itemgot('image')\n\nFor example, if our term is africa continent map, the above function gets the first popped up URL of the image of africa continent map as shown below.\n\nurls = search_images('africa continent map', max_images=1)\nurls[0]\n\nSearching for 'africa continent map'\n\n\n'https://cdn.onestopmap.com/wp-content/uploads/2015/05/464-map-africa-continent-political-shaded-relief.jpg'\n\n\nOnce, we get the URLs of an image, let us setup a way through which we can actually download the URLs we obtained and view them. We will storing the downloaded files in jpg formats.\nThe following snippets do that for us.\n\ndest = 'africa.jpg'\ndownload_url(urls[0], dest, show_progress=False)\n\nim = Image.open(dest)\nim.to_thumb(256,256)\n\n\n\n\n\n\n\n\nThe Africa continent looks good. Let us have sneak peak on the remaining 6 continents just to make sure that DuckDuckGo is getting the right images for us.\n\ndownload_url(search_images('antarctica continent map', max_images=1)[0], 'antarctica.jpg', show_progress=False)\nImage.open('antarctica.jpg').to_thumb(256,256)\n\nSearching for 'antarctica continent map'\n\n\n\n\n\n\n\n\n\n\ndownload_url(search_images('asia continent map', max_images=1)[0], 'asia.jpg', show_progress=False)\nImage.open('asia.jpg').to_thumb(256,256)\n\nSearching for 'asia continent map'\n\n\n\n\n\n\n\n\n\n\ndownload_url(search_images('australia continent map', max_images=1)[0], 'australia.jpg', show_progress=False)\nImage.open('australia.jpg').to_thumb(256,256)\n\nSearching for 'australia continent map'\n\n\n\n\n\n\n\n\n\n\ndownload_url(search_images('europe continent map', max_images=1)[0], 'europe.jpg', show_progress=False)\nImage.open('europe.jpg').to_thumb(256,256)\n\nSearching for 'europe continent map'\n\n\n\n\n\n\n\n\n\n\ndownload_url(search_images('north america continent map', max_images=1)[0], 'north_america.jpg', show_progress=False)\nImage.open('north_america.jpg').to_thumb(256,256)\n\nSearching for 'north america continent map'\n\n\n\n\n\n\n\n\n\n\ndownload_url(search_images('south america continent map', max_images=1)[0], 'south_america.jpg', show_progress=False)\nImage.open('south_america.jpg').to_thumb(256,256)\n\nSearching for 'south america continent map'\n\n\n\n\n\n\n\n\n\nEverything, looks good!\nNow that everything is setup, let us create our classifier. Generally, the following steps are taken when building an image classifier model."
  },
  {
    "objectID": "posts/teaching-ai-some-geography/continents_classifier.html#get-image-data",
    "href": "posts/teaching-ai-some-geography/continents_classifier.html#get-image-data",
    "title": "Teaching AI Some Geography",
    "section": "Get Image Data",
    "text": "Get Image Data\nLet us go on and get our image data.\n\nsearches = ['africa', 'antarctica', 'asia', 'australia', 'europe', 'north america', 'south america']\npath = Path('which_continent_is_it')\nfrom time import sleep\n\nfor o in searches:\n    dest = (path/o)\n    dest.mkdir(exist_ok=True, parents=True)\n    download_images(dest, urls=search_images(f'{o} continent map'))\n    sleep(10)  # Pause between searches to avoid over-loading server\n    resize_images(path/o, max_size=400, dest=path/o)\n\nSearching for 'africa continent map'\nSearching for 'antarctica continent map'\n\n\n/usr/local/lib/python3.7/dist-packages/PIL/Image.py:1015: UserWarning: Couldn't allocate palette entry for transparency\n  warnings.warn(\"Couldn't allocate palette entry for transparency\")\n\n\nSearching for 'asia continent map'\nSearching for 'australia continent map'\n\n\n/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  \"Palette images with Transparency expressed in bytes should be \"\n\n\nSearching for 'europe continent map'\nSearching for 'north america continent map'\nSearching for 'south america continent map'\n\n\n/usr/local/lib/python3.7/dist-packages/PIL/Image.py:1015: UserWarning: Couldn't allocate palette entry for transparency\n  warnings.warn(\"Couldn't allocate palette entry for transparency\")\n\n\nSometimes, we might get a few broken images. We can track and discard them as follows.\n\nfailed = verify_images(get_image_files(path))\nfailed.map(Path.unlink)\nlen(failed)\n\n7"
  },
  {
    "objectID": "posts/teaching-ai-some-geography/continents_classifier.html#create-datablock",
    "href": "posts/teaching-ai-some-geography/continents_classifier.html#create-datablock",
    "title": "Teaching AI Some Geography",
    "section": "Create DataBlock",
    "text": "Create DataBlock\nNext we create a DataBlock that helps us put our images into the model.\n\ndls = DataBlock(\n    blocks=(ImageBlock, CategoryBlock), \n    get_items=get_image_files, \n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=[Resize(192, method='squish')]\n).dataloaders(path, bs=32)\n\ndls.show_batch(max_n=21)"
  },
  {
    "objectID": "posts/teaching-ai-some-geography/continents_classifier.html#create-the-learner",
    "href": "posts/teaching-ai-some-geography/continents_classifier.html#create-the-learner",
    "title": "Teaching AI Some Geography",
    "section": "Create The Learner",
    "text": "Create The Learner\nNow, we create the actual model that will learn from the image data we gave it.\n\nlearn = vision_learner(dls, resnet18, metrics=error_rate)\nlearn.fine_tune(3)\n\n/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n2.544921\n1.500386\n0.538462\n00:44\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n1.187040\n0.556937\n0.179487\n01:04\n\n\n1\n0.718358\n0.290570\n0.089744\n01:04\n\n\n2\n0.497790\n0.240653\n0.076923\n01:02"
  },
  {
    "objectID": "posts/teaching-ai-some-geography/continents_classifier.html#test-the-model",
    "href": "posts/teaching-ai-some-geography/continents_classifier.html#test-the-model",
    "title": "Teaching AI Some Geography",
    "section": "Test The Model",
    "text": "Test The Model\nOur model is ready to be tested!\nLet us input the images we stored at the beginning and see its results.\n\nwhich_continent_is_it,_,probs = learn.predict(PILImage.create('africa.jpg'))\nprint(f\"This is: {which_continent_is_it}.\")\nprint(f\"Probability: {probs[0]:.4f}\")\n\n\n\n\n\n\n\n\nThis is: africa.\nProbability: 0.9926\n\n\n\nwhich_continent_is_it,_,probs = learn.predict(PILImage.create('antarctica.jpg'))\nprint(f\"This is: {which_continent_is_it}.\")\nprint(f\"Probability: {probs[1]:.4f}\")\n\n\n\n\n\n\n\n\nThis is: antarctica.\nProbability: 0.9998\n\n\n\nwhich_continent_is_it,_,probs = learn.predict(PILImage.create('asia.jpg'))\nprint(f\"This is: {which_continent_is_it}.\")\nprint(f\"Probability: {probs[2]:.4f}\")\n\n\n\n\n\n\n\n\nThis is: asia.\nProbability: 1.0000\n\n\n\nwhich_continent_is_it,_,probs = learn.predict(PILImage.create('australia.jpg'))\nprint(f\"This is: {which_continent_is_it}.\")\nprint(f\"Probability: {probs[3]:.4f}\")\n\n\n\n\n\n\n\n\nThis is: australia.\nProbability: 0.9995\n\n\n\nwhich_continent_is_it,_,probs = learn.predict(PILImage.create('europe.jpg'))\nprint(f\"This is: {which_continent_is_it}.\")\nprint(f\"Probability: {probs[4]:.4f}\")\n\n\n\n\n\n\n\n\nThis is: europe.\nProbability: 0.9992\n\n\n\nwhich_continent_is_it,_,probs = learn.predict(PILImage.create('north_america.jpg'))\nprint(f\"This is: {which_continent_is_it}.\")\nprint(f\"Probability: {probs[5]:.4f}\")\n\n\n\n\n\n\n\n\nThis is: north america.\nProbability: 0.9999\n\n\n\nwhich_continent_is_it,_,probs = learn.predict(PILImage.create('south_america.jpg'))\nprint(f\"This is: {which_continent_is_it}.\")\nprint(f\"Probability: {probs[6]:.4f}\")\n\n\n\n\n\n\n\n\nThis is: south america.\nProbability: 0.9978\n\n\nLooks pretty impressive isn’t it?!\nIf you have any ideas of your own feel free to try them out."
  },
  {
    "objectID": "posts/how-to-run-a-linux-subsystem-in-windows/index.html",
    "href": "posts/how-to-run-a-linux-subsystem-in-windows/index.html",
    "title": "How To Run A Linux Subsystem In Windows",
    "section": "",
    "text": "One of the many first steps when venturing into doing Data Science is to have access to a Unix/Linux/Ubuntu OS.\nBut having a Windows OS and wanting to setup and run this hardcore geeky OS might be challenging.\nIn this blog, I will show a very quick and a simple way of setting up a Linux Subsystem in your Windows OS that I learned from Jeremy Howard! If you wish to follow along, you will have a complete full fledge Linux OS running in your Windows in the next 3-5 minutes. No complicated hacking stuff, no dual booting, no splitting of your computer into two halves using a light beam, none of that stuff. And if you are wondering if you will lose all the Windows features, don’t worry, you won’t.\nLet us get started!\n\n\n\nSource: https://giphy.com/gifs/wikitude-augmented-reality-penguin-linux-4Zgy9QqzWU8C3ugvCa"
  },
  {
    "objectID": "posts/how-to-run-a-linux-subsystem-in-windows/index.html#introduction",
    "href": "posts/how-to-run-a-linux-subsystem-in-windows/index.html#introduction",
    "title": "How To Run A Linux Subsystem In Windows",
    "section": "",
    "text": "One of the many first steps when venturing into doing Data Science is to have access to a Unix/Linux/Ubuntu OS.\nBut having a Windows OS and wanting to setup and run this hardcore geeky OS might be challenging.\nIn this blog, I will show a very quick and a simple way of setting up a Linux Subsystem in your Windows OS that I learned from Jeremy Howard! If you wish to follow along, you will have a complete full fledge Linux OS running in your Windows in the next 3-5 minutes. No complicated hacking stuff, no dual booting, no splitting of your computer into two halves using a light beam, none of that stuff. And if you are wondering if you will lose all the Windows features, don’t worry, you won’t.\nLet us get started!\n\n\n\nSource: https://giphy.com/gifs/wikitude-augmented-reality-penguin-linux-4Zgy9QqzWU8C3ugvCa"
  },
  {
    "objectID": "posts/how-to-run-a-linux-subsystem-in-windows/index.html#step-0-getting-a-terminal",
    "href": "posts/how-to-run-a-linux-subsystem-in-windows/index.html#step-0-getting-a-terminal",
    "title": "How To Run A Linux Subsystem In Windows",
    "section": "Step 0: Getting A Terminal",
    "text": "Step 0: Getting A Terminal\nWe will need a terminal handy right after we are done setting up Linux! There are many options to choose from. Let us download and install the Windows Terminal from the Microsoft Store before proceeding.\n\nPress the “⊞” key and type “store”.\n\n\n\nMicrosoft Store search\n\n\nOpen the Microsoft Store and search for “windows terminal”.\n\n\n\nDownload & install Windows Terminal\n\n\nDownload, and install it. We will use this soon!"
  },
  {
    "objectID": "posts/how-to-run-a-linux-subsystem-in-windows/index.html#step-1-getting-the-linux-subsystem",
    "href": "posts/how-to-run-a-linux-subsystem-in-windows/index.html#step-1-getting-the-linux-subsystem",
    "title": "How To Run A Linux Subsystem In Windows",
    "section": "Step 1: Getting the Linux Subsystem",
    "text": "Step 1: Getting the Linux Subsystem\nWe will be setting up our subsystem from the Windows Powershell application.\n\nPress the “⊞” key button and search for “powershell”.\n\n\n\nPowershell search\n\n\nClick on Run as Administrator. It will prompt to verify. Click Yes.\nOnce you are inside the Windows Powershell, type the wsl --install command and press “⏎”.\n\n\n\nwsl-command\n\n\nThis will download and install 2 things, the Windows Subsystem for Linux and Ubuntu as shown below. To take effect we need to reboot our system.\nAfter the installation is done, close all the files and applications, and restart the computer."
  },
  {
    "objectID": "posts/how-to-run-a-linux-subsystem-in-windows/index.html#step-2-hello-linux",
    "href": "posts/how-to-run-a-linux-subsystem-in-windows/index.html#step-2-hello-linux",
    "title": "How To Run A Linux Subsystem In Windows",
    "section": "Step 2: Hello, Linux",
    "text": "Step 2: Hello, Linux\nUpon restarting your computer a powershell window will pop up automatically, welcoming you and launching the Linux Subsystem. Once it is launched, it will ask to set up a username and a password. This is like a new computer that is running!\n\nPut a username and a password and you are done!\n\n\n\nAll set\n\n\n\nWhat you have now is a full fledged Linux Subsystem running in your Windows."
  },
  {
    "objectID": "posts/how-to-run-a-linux-subsystem-in-windows/index.html#step-3-accessing-linux",
    "href": "posts/how-to-run-a-linux-subsystem-in-windows/index.html#step-3-accessing-linux",
    "title": "How To Run A Linux Subsystem In Windows",
    "section": "Step 3: Accessing Linux",
    "text": "Step 3: Accessing Linux\nRemember that Windows Terminal we kept ready at the beginning?! We will be using that to acsess our Linux CLI.\n\nOpen the Windows Terminal. By default, the Windows Powershell will run.\n\n\n\nPowershell as default\n\n\nThere will be a little arrown pointing as shown. Click it, and will show the list of options we can select from. To get Linux, we will have to select manually from this list. Instead, let us setup Linux as the default profile whenever we open our Windows Terminal. To do that and go to Settings.\n\n\n\nSettings\n\n\nMake Linux or Ubuntu as the default one.\n\n\n\nmaking Linux/Ubuntu as default\n\n\n\nNext time you open the Windows Terminal, it will welcome you with Linux/Ubuntu.\n\n\n\n\n\n\n\n\n\nLinux\n\n\n\n\n\n\n\nUbuntu"
  },
  {
    "objectID": "posts/how-to-run-a-linux-subsystem-in-windows/index.html#explore",
    "href": "posts/how-to-run-a-linux-subsystem-in-windows/index.html#explore",
    "title": "How To Run A Linux Subsystem In Windows",
    "section": "Explore",
    "text": "Explore\nYou are all set to dwell into the Linux metaverse! If you are new to Linux, check out some tutorials, like this one to learn about it."
  },
  {
    "objectID": "projects/members-only.html",
    "href": "projects/members-only.html",
    "title": "Members Only",
    "section": "",
    "text": "{{&lt; fa globe &gt;}} Live {{&lt; iconify fa github &gt;}} Source Code \n\n\n\n\n\n\nNote\n\n\n\nProject Description will be added soon.\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "projects/messaging-app.html",
    "href": "projects/messaging-app.html",
    "title": "Messaging App",
    "section": "",
    "text": "{{&lt; fa globe &gt;}} Live {{&lt; iconify fa github &gt;}} Backend {{&lt; iconify fa github &gt;}} Frontend \n\n\n\n\n\n\nNote\n\n\n\nProject Description will be added soon.\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "projects/blog-api.html",
    "href": "projects/blog-api.html",
    "title": "Blog API",
    "section": "",
    "text": "{{&lt; iconify fa github &gt;}} Source Code {{&lt; fa globe &gt;}} Live Viewing Site (Sample) {{&lt; fa globe &gt;}} Live Authoring Site (Sample) \n\n\n\n\n\n\nNote\n\n\n\nProject Description will be added soon.\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "projects/shopping-cart.html",
    "href": "projects/shopping-cart.html",
    "title": "Shopping Cart",
    "section": "",
    "text": "{{&lt; fa globe &gt;}} Live {{&lt; iconify fa github &gt;}} Source Code \n\n\n\n\n\n\nNote\n\n\n\nProject Description will be added soon.\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "projects/sign-up-form.html",
    "href": "projects/sign-up-form.html",
    "title": "Sign-up Form",
    "section": "",
    "text": "{{&lt; fa globe &gt;}} Live {{&lt; iconify fa github &gt;}} Source Code \n\n\n\n\n\n\nNote\n\n\n\nProject Description will be added soon.\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "projects/library.html",
    "href": "projects/library.html",
    "title": "Library",
    "section": "",
    "text": "{{&lt; fa globe &gt;}} Live {{&lt; iconify fa github &gt;}} Source Code \n\n\n\n\n\n\nNote\n\n\n\nProject Description will be added soon.\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "projects/e-shop-site.html",
    "href": "projects/e-shop-site.html",
    "title": "E Shop Site",
    "section": "",
    "text": "{{&lt; fa globe &gt;}} Live {{&lt; iconify fa github &gt;}} Source Code \n\n\n\n\n\n\nNote\n\n\n\nProject Description will be added soon.\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "projects/tic-tac-toe.html",
    "href": "projects/tic-tac-toe.html",
    "title": "Tic Tac Toe",
    "section": "",
    "text": "{{&lt; fa globe &gt;}} Live {{&lt; iconify fa github &gt;}} Source Code \n\n\n\n\n\n\nNote\n\n\n\nProject Description will be added soon.\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "projects/todo-list.html",
    "href": "projects/todo-list.html",
    "title": "Todo List",
    "section": "",
    "text": "{{&lt; fa globe &gt;}} Live {{&lt; iconify fa github &gt;}} Source Code \n\n\n\n\n\n\nNote\n\n\n\nProject Description will be added soon.\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "projects/homepage.html",
    "href": "projects/homepage.html",
    "title": "Homepage",
    "section": "",
    "text": "{{&lt; fa globe &gt;}} Live {{&lt; iconify fa github &gt;}} Source Code \n\n\n\n\n\n\nNote\n\n\n\nProject Description will be added soon.\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Abdullah Zeeshan, CF APMP",
    "section": "",
    "text": "Hi! I am Abdullah Zeeshan, a certified CF APMP professional with a diverse and cross-functional experience of 5 years in team leading, project management, recruitment, marketing, technology, stakeholder management, operations, pre-sales, content creation, teaching, and coordination.\nMore about me!."
  },
  {
    "objectID": "index.html#recent-posts",
    "href": "index.html#recent-posts",
    "title": "Abdullah Zeeshan, CF APMP",
    "section": "Recent Posts",
    "text": "Recent Posts\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nMar 12, 2025\n\n\nHow to publish a Quarto blog post with GitHub Pages?\n\n\nAbdullah Zeeshan\n\n\n\n\nMar 12, 2025\n\n\nHow to write Action Captions on graphics of proposals?\n\n\nAbdullah Zeeshan\n\n\n\n\nDec 5, 2022\n\n\nOh! Segmentation Tasks, Segmentation Tasks\n\n\nAbdullah Zeeshan\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#recent-projects",
    "href": "index.html#recent-projects",
    "title": "Abdullah Zeeshan, CF APMP",
    "section": "Recent Projects",
    "text": "Recent Projects\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nDec 5, 2024\n\n\nMessaging App\n\n\nAbdullah Zeeshan\n\n\n\n\nNov 11, 2024\n\n\nBlog API\n\n\nAbdullah Zeeshan\n\n\n\n\nNov 5, 2024\n\n\nFile Uploader\n\n\nAbdullah Zeeshan\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/landing-page.html",
    "href": "projects/landing-page.html",
    "title": "Landing Page",
    "section": "",
    "text": "{{&lt; fa globe &gt;}} Live {{&lt; iconify fa github &gt;}} Source Code \n\n\n\n\n\n\nNote\n\n\n\nProject Description will be added soon.\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "projects/rock-paper-scissors.html",
    "href": "projects/rock-paper-scissors.html",
    "title": "Rock Paper Scissors",
    "section": "",
    "text": "{{&lt; fa globe &gt;}} Live {{&lt; iconify fa github &gt;}} Source Code \n\n\n\n\n\n\nNote\n\n\n\nProject Description will be added soon.\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "projects/weather-app.html",
    "href": "projects/weather-app.html",
    "title": "Weather App",
    "section": "",
    "text": "{{&lt; fa globe &gt;}} Live {{&lt; iconify fa github &gt;}} Source Code \n\n\n\n\n\n\nNote\n\n\n\nProject Description will be added soon.\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "projects/battleship.html",
    "href": "projects/battleship.html",
    "title": "Battleship",
    "section": "",
    "text": "{{&lt; fa globe &gt;}} Live {{&lt; iconify fa github &gt;}} Source Code \n\n\n\n\n\n\nNote\n\n\n\nProject Description will be added soon.\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "projects/calculator.html",
    "href": "projects/calculator.html",
    "title": "Calculator",
    "section": "",
    "text": "{{&lt; fa globe &gt;}} Live {{&lt; iconify fa github &gt;}} Source Code \n\n\n\n\n\n\nNote\n\n\n\nProject Description will be added soon.\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "projects/etch-a-sketch.html",
    "href": "projects/etch-a-sketch.html",
    "title": "Etch A Sketch",
    "section": "",
    "text": "{{&lt; fa globe &gt;}} Live {{&lt; iconify fa github &gt;}} Source Code \n\n\n\n\n\n\nNote\n\n\n\nProject Description will be added soon.\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "projects/memory-card.html",
    "href": "projects/memory-card.html",
    "title": "Memory Card",
    "section": "",
    "text": "{{&lt; fa globe &gt;}} Live {{&lt; iconify fa github &gt;}} Source Code \n\n\n\n\n\n\nNote\n\n\n\nProject Description will be added soon.\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "projects/inventory-application.html",
    "href": "projects/inventory-application.html",
    "title": "Inventory Application",
    "section": "",
    "text": "{{&lt; fa globe &gt;}} Live {{&lt; iconify fa github &gt;}} Source Code \n\n\n\n\n\n\nNote\n\n\n\nProject Description will be added soon.\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "projects/file-uploader.html",
    "href": "projects/file-uploader.html",
    "title": "File Uploader",
    "section": "",
    "text": "{{&lt; fa globe &gt;}} Live {{&lt; iconify fa github &gt;}} Source Code \n\n\n\n\n\n\nNote\n\n\n\nProject Description will be added soon.\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "projects/cv-application.html",
    "href": "projects/cv-application.html",
    "title": "CV Application",
    "section": "",
    "text": "{{&lt; fa globe &gt;}} Live {{&lt; iconify fa github &gt;}} Source Code \n\n\n\n\n\n\nNote\n\n\n\nProject Description will be added soon.\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "posts/colored-cups/index.html#introduction",
    "href": "posts/colored-cups/index.html#introduction",
    "title": "Colored Cups",
    "section": "Introduction",
    "text": "Introduction\nI have had my share in teaching high school students a few years ago and one of the challenges that I faced back then was of getting a real time feedback of my student’s learning, as I was teaching in the class. Since I could not (and can not now as well) read their minds to know if they are following well along, I had to rely on them. They had to let me know if they are following along well. That brings another challenge! A student first must be self aware of his/her learning. In order to enable this, the students must be made owners of their learning."
  },
  {
    "objectID": "posts/colored-cups/index.html#colored-cups",
    "href": "posts/colored-cups/index.html#colored-cups",
    "title": "Colored Cups",
    "section": "Colored Cups",
    "text": "Colored Cups\nColored Cups introduced by Dylan Wiliam in his book Embedded Formative Assessment (2011), is an effective technique that can be used in a classroom that attempts to:\n\nGet real-time feedback of student’s learning for teachers.\nPromotes self-regulated learning for students."
  },
  {
    "objectID": "posts/colored-cups/index.html#working",
    "href": "posts/colored-cups/index.html#working",
    "title": "Colored Cups",
    "section": "Working",
    "text": "Working\nThe idea is simple!\nAll the students in the classrooms have 3 colored cups, a green cup, a yellow cup, and a red cup which are stacked together at the beginning of the class.\nEach of these colors reflect the various levels of understanding. Green means the student is understanding well, yellow means s/he is not quite sure what is going on, and red means the student has no idea of what is going on.\nAs the lesson is being taught, the students put a colored cup on their desks that corresponds to how they are following along, and the teacher can see the classroom to get a sense of how the students are following along.\nPrior to when a student puts a colored cup on the desk, s/he must self-assess his learning."
  },
  {
    "objectID": "posts/colored-cups/index.html#adaptations-in-the-fast.ai-course",
    "href": "posts/colored-cups/index.html#adaptations-in-the-fast.ai-course",
    "title": "Colored Cups",
    "section": "Adaptations In The fast.ai Course",
    "text": "Adaptations In The fast.ai Course\nI first got to know about this in Practical Deep Learning for Coders course. In the course, a virtual setup was made and the teacher, Jeremy could see it from his end in the teacher version."
  },
  {
    "objectID": "posts/how-to-write-action-captions-on-graphics-of-proposals/index.html",
    "href": "posts/how-to-write-action-captions-on-graphics-of-proposals/index.html",
    "title": "How to write Action Captions on graphics of proposals?",
    "section": "",
    "text": "An Action Caption is a short informative description about graphics in proposals that helps evaluators understand what the graphic means."
  },
  {
    "objectID": "posts/how-to-write-action-captions-on-graphics-of-proposals/index.html#what-is-an-action-caption",
    "href": "posts/how-to-write-action-captions-on-graphics-of-proposals/index.html#what-is-an-action-caption",
    "title": "How to write Action Captions on graphics of proposals?",
    "section": "",
    "text": "An Action Caption is a short informative description about graphics in proposals that helps evaluators understand what the graphic means."
  },
  {
    "objectID": "posts/how-to-write-action-captions-on-graphics-of-proposals/index.html#importance",
    "href": "posts/how-to-write-action-captions-on-graphics-of-proposals/index.html#importance",
    "title": "How to write Action Captions on graphics of proposals?",
    "section": "Importance",
    "text": "Importance\nAction captions must be included with every graphic in a proposal."
  },
  {
    "objectID": "posts/how-to-write-action-captions-on-graphics-of-proposals/index.html#parts-of-an-action-caption",
    "href": "posts/how-to-write-action-captions-on-graphics-of-proposals/index.html#parts-of-an-action-caption",
    "title": "How to write Action Captions on graphics of proposals?",
    "section": "Parts of an Action Caption",
    "text": "Parts of an Action Caption\nAn action caption typically has the following three parts:\n\nFigure number\nInformative heading\nCaption: A complete sentence that 1) explains the relevance of the graphic to the customer 2) links benefits to solutions or features of a solution."
  },
  {
    "objectID": "posts/how-to-write-action-captions-on-graphics-of-proposals/index.html#examples",
    "href": "posts/how-to-write-action-captions-on-graphics-of-proposals/index.html#examples",
    "title": "How to write Action Captions on graphics of proposals?",
    "section": "Examples",
    "text": "Examples\nHere are some examples that capture the three parts of a typical action caption in proposals. These are from various industries.\n\nFigure 3. Unified Sales Intelligence Dashboard: Centralizing Customer and Inventory Data to Boost Agent Productivity by 25%\n\n\nFigure 4. Voice-Activated Patient Note Interface: This AI-powered tool allows clinicians to dictate notes hands-free, cutting charting time by 50% and enabling an additional 15 minutes of patient-facing care per encounter.\n\n\nFigure 7. Real-Time Asset Tracking Map with Predictive Analytics: Our portal provides live location data and forecasts potential disruptions due to weather or traffic, allowing your team to proactively reroute shipments and avoid $2M in potential annual delay-related losses."
  },
  {
    "objectID": "posts/how-to-publish-a-quarto-blog-post-with-github-pages/index.html#step-1.-ask-quarto-to-render",
    "href": "posts/how-to-publish-a-quarto-blog-post-with-github-pages/index.html#step-1.-ask-quarto-to-render",
    "title": "How to publish a Quarto blog post with GitHub Pages?",
    "section": "Step 1. Ask Quarto to Render",
    "text": "Step 1. Ask Quarto to Render\nquarto render"
  },
  {
    "objectID": "posts/how-to-publish-a-quarto-blog-post-with-github-pages/index.html#step-2-github-related",
    "href": "posts/how-to-publish-a-quarto-blog-post-with-github-pages/index.html#step-2-github-related",
    "title": "How to publish a Quarto blog post with GitHub Pages?",
    "section": "Step 2: GitHub Related",
    "text": "Step 2: GitHub Related\ngit add docs\ngit commit -m \"Publish site to docs/\"\ngit push"
  },
  {
    "objectID": "posts/how-to-publish-a-quarto-blog-post-with-github-pages/index.html#step-3-ask-quarto-to-publish-on-gh-pages",
    "href": "posts/how-to-publish-a-quarto-blog-post-with-github-pages/index.html#step-3-ask-quarto-to-publish-on-gh-pages",
    "title": "How to publish a Quarto blog post with GitHub Pages?",
    "section": "Step 3: Ask Quarto to publish on gh-pages",
    "text": "Step 3: Ask Quarto to publish on gh-pages\nquarto publish gh-pages"
  },
  {
    "objectID": "posts/how-to-publish-a-quarto-blog-post-with-github-pages/index.html#references",
    "href": "posts/how-to-publish-a-quarto-blog-post-with-github-pages/index.html#references",
    "title": "How to publish a Quarto blog post with GitHub Pages?",
    "section": "References",
    "text": "References\n\nGitHub Pages – Quarto"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nHow to write Action Captions on graphics of proposals?\n\n\n\n\n\n\nblog\n\n\nquarto\n\n\n\nA summary of my workflow\n\n\n\n\n\nMar 12, 2025\n\n\nAbdullah Zeeshan\n\n\n\n\n\n\n\n\n\n\n\n\nHow to publish a Quarto blog post with GitHub Pages?\n\n\n\n\n\n\nblog\n\n\nquarto\n\n\n\nA summary of my workflow\n\n\n\n\n\nMar 12, 2025\n\n\nAbdullah Zeeshan\n\n\n\n\n\n\n\n\n\n\n\n\nOh! Segmentation Tasks, Segmentation Tasks\n\n\n\n\n\n\ncomputer vision\n\n\n\nCan computers detect objects in an image?\n\n\n\n\n\nDec 5, 2022\n\n\nAbdullah Zeeshan\n\n\n\n\n\n\n\n\n\n\n\n\nColored Cups\n\n\n\n\n\n\neducation\n\n\nfast.ai\n\n\n\nAn effective tool for every classroom\n\n\n\n\n\nNov 27, 2022\n\n\nAbdullah Zeeshan\n\n\n\n\n\n\n\n\n\n\n\n\nHow To Run A Linux Subsystem In Windows\n\n\n\n\n\n\ntutorial\n\n\nlinux\n\n\n\nA quick guide\n\n\n\n\n\nNov 24, 2022\n\n\nAbdullah Zeeshan\n\n\n\n\n\n\n\n\n\n\n\n\nTeaching AI Some Geography\n\n\n\n\n\n\nfast.ai\n\n\nexperiments\n\n\n\nBuilding an image classifier\n\n\n\n\n\nNov 14, 2022\n\n\nAbdullah Zeeshan\n\n\n\n\n\n\n\n\n\n\n\n\nFrolicking With AI Generated Art\n\n\n\n\n\n\nnews\n\n\ngeneral\n\n\nexplorations\n\n\n\nExploring DALL.E.2\n\n\n\n\n\nNov 12, 2022\n\n\nAbdullah Zeeshan\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "Messaging App\n\n\nFull Stack\n\n\n\nNode.js\n\n\nExpress\n\n\nPostgreSQL\n\n\nPrisma ORM\n\n\nREST API\n\n\nJWT\n\n\nPassport\n\n\nReact\n\n\nTailwind\n\n\n\nWeb-based messaging app where authenticated users can chat one-one by sending and receiving messages and files.\n\n\n\n\n\n\n\n\n\n\n\nBlog API\n\n\nBackend\n\n\n\nNode.js\n\n\nExpress\n\n\nPostgreSQL\n\n\nPrisma ORM\n\n\nREST API\n\n\nJWT\n\n\nPassport\n\n\n\nAn API-only backend for blogging platforms, featuring two front-ends: one for readers, and another for authors.\n\n\n\n\n\n\n\n\n\n\n\n\n\nFile Uploader\n\n\nFull Stack\n\n\n\nNode.js\n\n\nExpress\n\n\nPostgreSQL\n\n\nPrisma ORM\n\n\nPassport\n\n\nEJS\n\n\nCloudinary\n\n\n\nCloud storage application enabling authenticated users to upload files and organize them into folders.\n\n\n\n\n\n\n\n\n\n\n\n\n\nShopping Cart\n\n\nFrontend\n\n\n\nReact\n\n\nReact Router\n\n\nRTL\n\n\nVitest\n\n\nCSS Modules\n\n\nVite\n\n\n\nA web-based e-commerce app featuring essential functionalities, including product display, cart management, and checkout.\n\n\n\n\n\n\n\n\n\n\n\n\n\nMemory Card\n\n\nFrontend\n\n\n\nReact\n\n\nVite\n\n\n\nA fun and interactive memory card game built with React, featuring dynamic card shuffling, score tracking, and Pokémon API integration.\n\n\n\n\n\n\n\n\n\n\n\n\n\nCV Application\n\n\nFrontend\n\n\n\nReact\n\n\nVite\n\n\n\nA dynamic web app that allows users to input their information and generates a live CV with an option to download the PDF.\n\n\n\n\n\n\n\n\n\n\n\n\n\nMembers Only\n\n\nFull Stack\n\n\n\nNode.js\n\n\nExpress\n\n\nSQL\n\n\nPostgreSQL\n\n\nPassport\n\n\n\nAn exclusive clubhouse where members can write anonymous posts.\n\n\n\n\n\n\n\n\n\n\n\n\n\nInventory Application\n\n\nFull Stack\n\n\n\nNode.js\n\n\nExpress\n\n\nSQL\n\n\nPostgreSQL\n\n\nEJS\n\n\n\nAn inventory management app for an imaginary store created with Express and PostgreSQL\n\n\n\n\n\n\n\n\n\n\n\n\n\nBattleship\n\n\nFrontend\n\n\n\nHTML\n\n\nCSS\n\n\nJavaScript (ES6)\n\n\nWebpack\n\n\nJest\n\n\nOOP\n\n\nTDD\n\n\n\nBrowser-based Battleship game built with HTML, CSS, and JavaScript, playable against the computer.\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeather App\n\n\nFrontend\n\n\n\nJavaScript (Asynchronous )\n\n\nAPI\n\n\n\nA weather forecast site using the Visual Crossing API\n\n\n\n\n\n\n\n\n\n\n\n\n\nTodo List\n\n\nFrontend\n\n\n\nJavaScript (ES6)\n\n\nWebpack\n\n\nOOP\n\n\nSOLID Principles\n\n\n\nTodo list app built with HTML, CSS, and JavaScript, allowing users to create, organize, and manage tasks within projects.\n\n\n\n\n\n\n\n\n\n\n\n\n\nTic Tac Toe\n\n\nFrontend\n\n\n\nHTML\n\n\nCSS\n\n\nJavaScript\n\n\nOOP\n\n\n\nA Tic Tac Toe game that you can play in your browser! Created with HTML, CSS, and JavaScript utilizing Factories & Module Patterns (IIFEs).\n\n\n\n\n\n\n\n\n\n\n\n\n\nE Shop Site\n\n\nFrontend\n\n\n\nHTML\n\n\nCSS\n\n\nResponsive\n\n\nBootstrap\n\n\n\nResponsive mockup website for an online cake shop, showcasing products and user-friendly navigation.\n\n\n\n\n\n\n\n\n\n\n\n\n\nLibrary\n\n\nFrontend\n\n\n\nHTML\n\n\nCSS\n\n\nJavaScript\n\n\nOOP\n\n\n\nA small online personal library to track reading lists created with HTML, CSS & JavaScript using constructors.\n\n\n\n\n\n\n\n\n\n\n\n\n\nHomepage\n\n\nFrontend\n\n\n\nHTML\n\n\nCSS\n\n\nResponsive\n\n\n\nA responsive homepage site created with HTML & CSS.\n\n\n\n\n\n\n\n\n\n\n\n\n\nSign-up Form\n\n\nFrontend\n\n\n\nHTML\n\n\nCSS\n\n\n\nA sign-up form for an imaginary service.\n\n\n\n\n\n\n\n\n\n\n\n\n\nCalculator\n\n\nFrontend\n\n\n\nHTML\n\n\nCSS\n\n\nJavaScript\n\n\n\nAn on-screen calculator with keyboard support featuring basic arithmetic operations.\n\n\n\n\n\n\n\n\n\n\n\n\n\nRock Paper Scissors\n\n\nFrontend\n\n\n\nHTML\n\n\nCSS\n\n\nJavaScript\n\n\n\nThe Rock Paper Scissors game that can be played entirely in the console.\n\n\n\n\n\n\n\n\n\n\n\n\n\nEtch A Sketch\n\n\nFrontend\n\n\n\nHTML\n\n\nCSS\n\n\nJavaScript\n\n\n\nA browser version of something between a sketchpad and an Etch-A-Sketch.\n\n\n\n\n\n\n\n\n\n\n\n\n\nLanding Page\n\n\nFrontend\n\n\n\nHTML\n\n\nCSS\n\n\n\nA landing page.\n\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  }
]